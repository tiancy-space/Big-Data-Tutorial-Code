## 一、Spark SQL使用案例-电影评分

[数据源位置](http://files.grouplens.org/datasets/movielens/ml-25m.zip) 来源于`org.apache.spark 官方提供` . 

数据源中使用到的具体数据介绍如下:  `movies.csv` 和`ratings.csv`. 

### 1、数据源以及介绍

`movies.csv`  电影信息数据集: 电影id、电影名称、电影所属分类

```sql
该文件是电影数据，对应的为维表数据，大小为2.89MB，包括6万多部电影，其数据格式为[movieId,title,genres]
分别对应[电影id，电影名称，电影所属分类]，样例数据如下所示：逗号分隔
```

数据格式如下: 本身是`csv格式,并且提供了表头,字段之间分隔符使用标准的逗号分开`. 电影分类字段以`|`分割. 

```sql
movieId,title,genres
1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy
2,Jumanji (1995),Adventure|Children|Fantasy
```



`ratings.csv`  电影评分数据集 :  用户id、电影id、评分、时间戳. 

```sql
该文件为定影评分数据，对应为事实表数据，大小为646MB，其数据格式为:[userId,movieId,rating,timestamp]
分别对应[用户id，电影id，评分，时间戳]，样例数据如下所示：逗号分隔
```

数据格式如下: 本身是`csv格式,并且提供了表头,字段之间分隔符使用标准的逗号分开`. 

```sql
userId,movieId,rating,timestamp
1,296,5.0,1147880044
1,306,3.5,1147868817
```



### 2、需求说明

**完成以下需求，并将需求结果写入Mysql当中**

2.1、**查找电影评分个数超过5000,且平均评分较高的前十部电影名称及其对应的平均评分**

> 理解需求: 涉及到两张表: `movies`表和`retings`.  评分表中,一条`movieId`可能会存在多个用户评分. 
>
> 这里需要根据评分表中的`movieId`进行聚合, 统计每个`movieId`对应的`评分数量`以及平均评分. 
>
> 再和`movie表`进行聚合,获取**电影名称**

```sql
WITH ratings_filter_cnt AS (
SELECT
	    movieId,
	    count( * ) AS rating_cnt,
	    avg( rating ) AS avg_rating
FROM
	    ratings
GROUP BY
	    movieId
HAVING
	    count( * ) >= 5000
),
ratings_filter_score AS (
SELECT
     movieId, -- 电影id
     avg_rating -- 电影平均评分
FROM ratings_filter_cnt
ORDER BY avg_rating DESC -- 平均评分降序排序
LIMIT 10 -- 平均分较高的前十部电影
)
SELECT
	   m.movieId,
	   m.title,
	   r.avg_rating AS avgRating
FROM
	  ratings_filter_score r
JOIN movies m ON m.movieId = r.movieId
```

| **movieId** | **title**                                   | **avgRating** |
| ----------- | ------------------------------------------- | ------------- |
| 318         | Shawshank Redemption, The (1994)            | 4.41          |
| 858         | Godfather, The (1972)                       | 4.32          |
| 50          | Usual Suspects, The (1995)                  | 4.28          |
| 1221        | Godfather: Part II, The (1974)              | 4.26          |
| 527         | Schindler's List (1993)                     | 4.25          |
| 2019        | Seven Samurai (Shichinin no samurai) (1954) | 4.25          |
| 904         | Rear Window (1954)                          | 4.24          |
| 1203        | 12 Angry Men (1957)                         | 4.24          |
| 2959        | Fight Club (1999)                           | 4.23          |
| 1193        | One Flew Over the Cuckoo's Nest (1975)      | 4.22          |

 ![image-20220719144255660](https://tiancy-images.oss-cn-beijing.aliyuncs.com/img/202207191442734.png) 

**2.2、查找每个电影类别及其对应的平均评分**

> 分析: 需要将一行数据,根据`genres` 并以`|` 将一列数据,变成多行数据. **炸裂 + 侧写** 
>
> 再关联求每个电影ID对应的平均分. 

```sql
WITH explode_movies AS (
    -- 1、先将当前电影表中 分类字段通过炸裂 + 侧写炸开,形成列转行操作. 
    SELECT movieId,
    title,
    category
    FROM movies lateral VIEW explode ( split ( genres, "\\|" ) ) temp AS category
)
SELECT m.category    AS genres,
       avg(r.rating) AS avgRating
FROM explode_movies m JOIN ratings r ON m.movieId = r.movieId
GROUP BY m.category
```

| **genres**         | **avgRating** |
| ------------------ | ------------- |
| Film-Noir          | 3.93          |
| War                | 3.79          |
| Documentary        | 3.71          |
| Crime              | 3.69          |
| Drama              | 3.68          |
| Mystery            | 3.67          |
| Animation          | 3.61          |
| IMAX               | 3.6           |
| Western            | 3.59          |
| Musical            | 3.55          |
| Romance            | 3.54          |
| Adventure          | 3.52          |
| Thriller           | 3.52          |
| Fantasy            | 3.51          |
| Sci-Fi             | 3.48          |
| Action             | 3.47          |
| Children           | 3.43          |
| Comedy             | 3.42          |
| (no genres listed) | 3.33          |
| Horror             | 3.29          |



**2.3、查找被评分次数较多的前十部电影**

> 直接按照 `movieId`进行分组,统计每个`movieId`的评分人数,按照评分人数降序排序.取`Top10`

```sql
WITH rating_group AS (
    SELECT
       movieId,
       count( * ) AS ratingCnt
    FROM ratings
    GROUP BY movieId
),
rating_filter AS (
    SELECT
       movieId,
       ratingCnt
    FROM rating_group
    ORDER BY ratingCnt DESC
    LIMIT 10
)
SELECT
    m.movieId,
    m.title,
    r.ratingCnt
FROM
    rating_filter r
JOIN movies m ON r.movieId = m.movieId
```

### 3、代码分层以及代码实现

> 这里通过`Spark`读取数据源和写SQL出分析结果,并不难,这里更加关注: 如何设计代码,一步一步优化,代码不断迭代,并且根据不同功能进行代码分层.

主要分为以下几个包: `resources`、`bean`、`demos`、`metrics`、`spark`、`util`几个包. 

- `resources` 下主要用于放置配置信息,需要程序运行前的建表语句、日志处理配置以及`Hive`支持的配置. 这个配置文件可以通过`util包下ReadConfigProUtil`这个类获取各种配置项. 
- bean下主要用来存放程序设计时的实体, 比如: 通过`Spark`读取到`csv`文件后,每张表中每行数据,抽象成的实体类、每个需求最终查询的结果,每行也会封装成一个实体. 主要通过实体控制具体数据. 
- `spark`包下,主要封装了两个类,一个用来`获取spark上下文环境`,一个用来处理`spark读取或者写入`操作的类. 
- `metrics` 主要用来封装每个功能的具体流程,就是可以将多个步骤,一个一个步骤进行封装,并最终在`demos`中的`Main`类中调用. 

![image-20220719145626581](https://tiancy-images.oss-cn-beijing.aliyuncs.com/img/202207191456665.png) 

**spark这个包下,主要用来创建spark上下文环境,包括spark sql 的上下文环境.**

具体的使用步骤: 自定义一个类`Main` extends `SparkApp`即可. 

```scala
object Main extends SparkApp {
  def main(args: Array[String]): Unit = {
    val sc: SparkContext = spark.sparkContext
    val csvMapOps = Map("header" -> "true", "delimiter" -> ",", "inferSchema" -> "true")
    val moviesDF: DataFrame = spark.read.format("csv").options(csvMapOps).load("./03-Spark-SparkSql-UseCase/ml-25m/movies.csv")
    moviesDF.show(30, false)
    moviesDF.printSchema()
    sc.stop()
    spark.stop()
  }
}
```



具体代码实现的细节,可以直接看`gitHub`上的代码展示.  [代码位置](https://github.com/tiancy-space/Big-Data-Tutorial-Code/tree/master/03-Spark-SparkSql-UseCase)