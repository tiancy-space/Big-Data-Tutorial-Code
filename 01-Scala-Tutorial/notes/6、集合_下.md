## 集合 常用方法
[TOC]

### **一、处理集合本身的方法**

#### 1、集合间的交、并、差集

**<strong style="color:#ff0000;">intersect、union、diff</strong>** 

> **通过两个集合间的操作,返回一个新的集合.**

```scala
val list = List(1,2,3,4,5)
val list1 = List(3,4,5,6,7,8)
// 集合并集
println(list.union(list1)) // (1, 2, 3, 4, 5, 3, 4, 5, 6, 7, 8)
// 集合交集
println(list.intersect(list1))
// 集合差集
println(list.diff(list1))
println(list1.diff(list))
```

#### 2、集合切分splitAt(n)

> 集合切分,使用的是splitAt(n)方法,该方法将一个集合拆分成两个集合.这两个集合使用`元组`存储.
>
> **其中`参数 n` : 表示当前第一个结合元素个数.**
>
> 如果传入的为`0或者负数`,也会拆分成两个集合,一个为空

```scala
val list = List(1,2,3,4,5)
val tuple = list.splitAt(3)
println(tuple)
//结果
(List(1, 2, 3),List(4, 5))
```

#### 3、集合滑动

> 指定元素个数,根据元素个数,对集合中的元素进行捆绑,一次向前滑动一次.结果是一个迭代器.

```scala
val list = List(1,2,3,4,5)
// 集合滑动
println(list.sliding(2))
println(list.sliding(2).mkString(","))
//结果
<iterator>
List(1, 2),List(2, 3),List(3, 4),List(4, 5)
```

#### 4、集合滚动

> **sliding(m,n)**
>
> m表示绑定几个元素.
>
> n表示向前移动几个元素.

```scala
// 集合滚动
println(list.sliding(3, 1).mkString(","))
println(list.sliding(3, 2).mkString(","))
//结果
List(1, 2, 3),List(2, 3, 4),List(3, 4, 5)
List(1, 2, 3),List(3, 4, 5)
List(1, 2, 3, 4),List(3, 4, 5)
```

#### 5、集合拉链 | 索引拉链

> **合并集合,将相同位置的元素,放入到一个`元组`中**

**拉链**

> 所谓拉链,就是两个集合,根据其元素位置相同的元素,放在一起.

```scala
val list1 = List(1,2,3,4,5)
val list2 = List(-1,-2,-3,-4,-5)
println(list1.zip(list2))
// List((1,-1), (2,-2), (3,-3), (4,-4), (5,-5))
```

**索引拉链**

```scala
val l1 = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
val l2 = List("ashe", "timo", "盖伦", "卡沙", "派克", "鳄鱼")
println(l1.zip(l2))
println(l2.zipWithIndex)
//结果
List((1,ashe), (2,timo), (3,盖伦), (4,卡沙), (5,派克), (6,鳄鱼))
List((ashe,0), (timo,1), (盖伦,2), (卡沙,3), (派克,4), (鳄鱼,5))
```

**拉链后的集合转化为Map**

```scala
val l1 = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
val l2 = List("ashe", "timo", "盖伦", "卡沙", "派克", "鳄鱼")
println(l1.zip(l2).toMap)
//结果
Map(5 -> 派克, 1 -> ashe, 6 -> 鳄鱼, 2 -> timo, 3 -> 盖伦, 4 -> 卡沙)
```

#### 6、集合中元素最值、计算

```scala
val l1 = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
println(l1.min) //1
println(l1.max) //10 
println(l1.sum) //55
//乘积
println(l1.product) // 3628800
```

#### **7、集合规约**

```
判断要使用`reduce`还是`fold`.
主要来判断 : 是集合内部聚合,还是使用集合和集合外部聚合
```
-  如果集合内部,也就是集合中的第一项和第二项先聚合,则使用 `reduce` 
-  如果是集合内的数据和集合外的数据计算,则使用`fold`


> 所谓规约,就是从集合指定位置开始,依次将两个元素将加得到结果,再与后一个相加.
>
> **需要指定规约方向,从左还是从右.**

```scala
val list = List(1, 2, 3, 4, 5)
```

```scala
// 集合规约
println(list.reduce(_ + _))
//15  1+2 = 3 , 3 + 3 = 6,6 + 4 = 10, 10 + 5 = 15
println(list.reduce(_ - _)) // -13
// 1-2 = -1 , -1 - 3 = -4,-4 - 4 = -8, -8 - 5 = -13
```

```scala
// 集合左规约,和 reduce逻辑一样.
println(list.reduceLeft(_ + _)) //15
println(list.reduceLeft(_ - _)) // -13
```

```scala
// 集合右规约,指的是计算方向不同,从后往前.
//相加结果相同
println(list.reduceRight(_ + _)) // 15
// 相减的顺序 : 4- 5 = -1, 3 - -1 = 4, 2 - 4 = -2, 1 - -2 = 3
println(list.reduceRight(_ - _)) // 3
```

#### 8、集合折叠

> 所谓折叠`fold(6)(_+_)`,就是在规约的基础上,加上或者减去`参数值`

```scala
//35. 集合折叠
println(list.fold(6)(_ + _)) // 21
//36. 集合左折叠
println(list.foldLeft(6)(_ + _)) //21
//37. 集合右折叠
println(list.foldRight(6)(_ + _)) // 21
println(list.foldRight(6)(_ - _)) // -3
```

#### 9、集合扫描

> **集合扫描`scan`,也是建立在`规约`基础上的,不过会先拿初始值与第一个元素进行计算,计算结果再规约.**

```scala
val list = List(1, 2, 3, 4, 5)
// 6 , 6 + 第一个元素 = 7,7+第二个元素 = 9,9 + 第三个元素 = 12 .....
val list2: List[Int] = list.scan(6)(_ + _) 
println(list2) // List(6, 7, 9, 12, 16, 21)
// 集合左扫描
println(list.scanLeft(6)(_ + _)) // List(6, 7, 9, 12, 16, 21)
// 集合右扫描
println(list.scanRight(6)(_ + _)) //List(21, 20, 18, 15, 11, 6)
```

### <strong style="color:#c00000;">二、集合功能函数</strong> 

#### <strong style="color:#00b0f0;">1、map函数</strong> 

> 将集合中的每一项元素,经过**map**处理后,形成**一个新的集合**.处理数据的条件是`通过我们给定的函数来处理的`

<img src="https://tiancy-images.oss-cn-beijing.aliyuncs.com/asSets/image-20210906153531350.png" alt="image-20210906153531350" style="zoom: 50%;" />  

**案例1 : 将给定集合中的单词转化为大写**

```scala
val list1 = List("hello","java","world","kafka","spark","scala","flume","hadoop","hive")
val worlds = list1.map(_.toUpperCase())
println(worlds) // List(HELLO, JAVA, WORLD, KAFKA, SPARK, SCALA, FLUME, HADOOP, HIVE)
```



#### <strong style="color:#00b0f0;">2、flatten函数</strong> 

> **<strong style="color:#ff0000;">flatten</strong>**,也被称为**集合扁平化**,主要是将集合中的多个集合 ,压扁.
>
> **或者换一种方式说,就是将集合中的多个集合,去除集合的操作.**

<img src="https://tiancy-images.oss-cn-beijing.aliyuncs.com/asSets/image-20210906155728416.png" alt="image-20210906155728416" style="zoom:50%;" />   

**案例 : 1 将两个集合中内容合并到一个大集合中**

```scala
val list1 = List("hello","java","world","kafka","spark","scala","flume","hadoop","hive")
val list2 = List(0, 1, 2, 3, 4, 5, 6, 7, 8)
val list3 = List(list1, list2)
println(list3.flatten)
//List(hello, java, world, kafka, spark, scala, flume, hadoop, hive, 0, 1, 2, 3, 4, 5, 6, 7, 8)
```

#### <strong style="color:#00b0f0;">3、 flatmap</strong>

> 此函数,是上述两个函数的组合.
>
> 扁平化映射可以理解为**先map**，然后再**flflatten**

<img src="https://tiancy-images.oss-cn-beijing.aliyuncs.com/asSets/image-20210906162020015.png" alt="image-20210906162020015" style="zoom:50%;" />  



**案例 1: 将下列集合中的数据进行处理,并最终放入到一个集合中.**

```scala
List("hadoop hive spark flflink flflume", "kudu hbase sqoop storm")
```

```scala
val list4 = List("hadoop hive spark flflink flflume", "kudu hbase sqoop storm")
//通过空格切割List中的每一项数据,切割完成后,会形成若干数组.
val list5 = list4.map(_.split(" ")).flatten
println(list5)
```

#### <strong style="color:#00b0f0;">4、过滤(filter)</strong>

> **将集合中符合过滤函数的数据过滤出来,最终会返回一个新的集合.**

**案例1 : 过滤以`s`开头的单词和偶数**

```scala
val list1 = List("sex","java","sss","kafka","spark","scala","flume","hadoop","hive")
//将集合中`s`开头的单词过滤出来
val result = list1.filter(_.startsWith("s"))
println(result)
val list2 = List(0, 1, 2, 3, 4, 5, 6, 7, 8)
//过滤出集合中的偶数
println(list2.filter(_ % 2 == 0))
//结果
List(sex, sss, spark, scala)
List(0, 2, 4, 6, 8)
```

#### <strong style="color:#00b0f0;">**5、 排序相关**</strong>

|  **函数名**  | **功能**                                 |
| :----------: | :--------------------------------------- |
|  **sorted**  | **用来对集合元素进行默认排序(默认升序)** |
|  **sortBy**  | **用来对指定字段排序**                   |
| **sortWith** | **用来对集合进行自定义排序**             |

##### **使用`sorted默认排序`**

> **所谓的默认排序指的是 对列表元素按照升序进行排列 . 如果需要降序排列, 则升序后, 再通过 reverse 实现.**

```scala
val list1 = List("sex","java","sss","kafka","spark","scala","flume","hadoop","hive")
println(list1.sorted)
// List(flume, hadoop, hive, java, kafka, scala, sex, spark, sss)
```

##### **使用`sortBy`指定字段排序**

> **使用`sortBy`方法,需要先通过`传入的函数`指定待排序字段**
>
> **如果排序规则有一个字段并且需要升序,则不用处理,默认就是升序.如果不是默认情况,则还需要通过`柯里化`特性,再指定`排序字段的排序规则`**

**案例1 :按照首字母排序**  <strong style="color:#ff0000;">指定排序字段,默认排序规则.</strong>  

```scala
//
val input = List("01 hadoop", "02 flflume", "03 sqoop", "04 flink", "05 spark")
println(input.sortBy(_.split(" ")(1)))
```

**案例2 :将list中的元素按照数字大小进行升序排序**

```scala
val list12 = List( 5, 2, 1, 7, 3, 9 ,4 )
println(list12.sortBy(num=>num)) //使用默认排序
```

**案例3 : 将list集合中的数字降序排序.**<strong style="color:#c00000;">需要指定排序字段的排序规则</strong> 

```scala
println(list12.sortBy(num => num)(Ordering.Int.reverse)) //降序
```

**案例4 : 将List中的元组吗,按照第一个元素升序排序,如果第一个元素相同则再按照字母降序排序** <strong style="color:#ff0000;">**指定待排序的字段类型和排序规则**</strong> 

```scala
/*
        Ordering.Tuple2 : 指定排序元素的类型为元组.
        (Ordering.Int,Ordering.String.reverse) 再通过指定元组的参数列表来指定排序规则.
*/
val input2 = List((30, "zhangsan"), (20, "wangwu"), (10, "lisi"), (20, "apple"), (10, "mark"))
val tuples = input2.sortBy(t => t)(Ordering.Tuple2(Ordering.Int, Ordering.String.reverse))
println(tuples)
// List((10,mark), (10,lisi), (20,wangwu), (20,apple), (30,zhangsan))
```

##### 使用sortWith自定义排序

> **这里用到的比较规则 :  元素与元素之间两两比较.**
>
> <strong style="color:#ff0000;">**升序就是从小到大,前一个小于后一个**</strong>  **`<`**
>
> <strong style="color:#ff0000;">**降序就是从大到小,前一个大于后一个**</strong> **`>`**

**案例1 : 将List中的元组吗,按照第一个元素升序排序,如果第一个元素相同则再按照字母降序排序**

`自定义排序`

```scala
val input2 = List((30, "zhangsan"), (20, "wangwu"), (10, "lisi"), (20, "apple"), (10, "mark"))
//需要两个元素参与比较
val tuples1 = input2.sortWith((t1, t2) => {
    //如果两个元素的 第一项相同,则按照第二项的字母降序排序,否则,按照第一项的数子升序排序.
    if (t1._1 == t2._1) t1._2 > t2._2 else t1._1 < t2._1
})
println(tuples1 + "============>")
//结果
List((10,mark), (10,lisi), (20,wangwu), (20,apple), (30,zhangsan))==========>
```

#### <strong style="color:#00b0f0;">6、 分组</strong> 

> 通过给定的`groupBy()`函数对集合分组.
>
> 分组的结果是一个Map,分组字段就是key,value是一个集合,用来存放符当前分组的元素.

![image-20210906172516790](https://tiancy-images.oss-cn-beijing.aliyuncs.com/asSets/image-20210906172516790.png)



**案例1 : 将如下集合中的单词按照首字母分组**

```scala
val list11 = List("hello scala", "hive spark")
val result = list11.flatMap(_.split(" ")).groupBy(_.charAt(0))
println(result) // Map(h -> List(hello, hive), s -> List(scala, spark))
```

**案例2 : 通过性别进行分组,统计人数**

```scala
val list = List("刘德华" -> "男", "刘亦菲" -> "女", "胡歌" -> "男", "金 *" -> "未知")
val result2 = list.groupBy(_._2) 
//Map(男 -> List((刘德华,男), (胡歌,男)), 未知 -> List((金 *,未知)), 女 -> List((刘亦菲,女)))
//再通过map映射成我们最终想要的结果,注意元素整体是一个元组,最总构建Map格式时,不能简化.
println(result2.map(x => x._1 -> x._2.size))
```



### **综合案例 `word count`**

> **读取文件中的单词,统计单词个数**

```scala
object WordCount {
    def main(args: Array[String]): Unit = {
        val datas = Source
        .fromFile("B:\\DevTools\\IdeaProjects\\0609_BigData\\Scala\\Input\\input.txt")
        .getLines()
        .toList
        .flatMap(_.split(" "))
        //List(Hello, World, Hello, Scala, Hello, Hadoop, Hadoop, Hadoop, Hadoop, Hello, Hive....)
        println(datas)
        //根据单词本身分组,形成Map ("Hello"->5),通过map映射,计算出现次数
        val result1 = datas.groupBy(key => key).map((word) => word._1 -> word._2.size)
        //转化成List,根据出现次数排序
        println(result1.toList.sortBy(w => w._2)(Ordering.Int.reverse))
    }
}
```

